#!/usr/bin/env python
"""Train a lightweight VAE on exported Gaussian teacher features.

The script expects an ``.npz`` file generated by ``export_gaussian_features.py`` and learns
an encoder/decoder pair that compresses the feature vectors into a low-dimensional latent
space. The trained model can later be plugged into the Stage 2 distillation pipeline to
provide compact teacher embeddings.

Example
-------
python tools/train_feature_vae.py \
    --data data/vae/lego_gaussians_cells.npz \
    --output checkpoints/vae/lego_gaussians_latent32.pth \
    --latent-dim 32 \
    --hidden-dim 256 \
    --epochs 20 \
    --batch-size 4096 \
    --kl-weight 0.1
"""
from __future__ import annotations

import argparse
import json
from pathlib import Path
from typing import Dict, List

import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import DataLoader, TensorDataset


class VAE(nn.Module):
    def __init__(self, input_dim: int, hidden_dim: int, latent_dim: int):
        super().__init__()
        self.encoder = nn.Sequential(
            nn.Linear(input_dim, hidden_dim),
            nn.ReLU(inplace=True),
            nn.Linear(hidden_dim, hidden_dim),
            nn.ReLU(inplace=True),
        )
        self.mu = nn.Linear(hidden_dim, latent_dim)
        self.logvar = nn.Linear(hidden_dim, latent_dim)

        self.decoder = nn.Sequential(
            nn.Linear(latent_dim, hidden_dim),
            nn.ReLU(inplace=True),
            nn.Linear(hidden_dim, hidden_dim),
            nn.ReLU(inplace=True),
            nn.Linear(hidden_dim, input_dim),
        )

    def encode(self, x: torch.Tensor) -> tuple[torch.Tensor, torch.Tensor]:
        h = self.encoder(x)
        return self.mu(h), self.logvar(h)

    def reparameterize(self, mu: torch.Tensor, logvar: torch.Tensor) -> torch.Tensor:
        std = torch.exp(0.5 * logvar)
        eps = torch.randn_like(std)
        return mu + eps * std

    def decode(self, z: torch.Tensor) -> torch.Tensor:
        return self.decoder(z)

    def forward(self, x: torch.Tensor) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:
        mu, logvar = self.encode(x)
        z = self.reparameterize(mu, logvar)
        recon = self.decode(z)
        return recon, mu, logvar


def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(description="Train a VAE on Gaussian teacher features")
    parser.add_argument("--data", type=Path, required=True, help="Path to features .npz file")
    parser.add_argument("--output", type=Path, required=True, help="Output checkpoint path")
    parser.add_argument("--latent-dim", type=int, default=32, help="Latent dimensionality")
    parser.add_argument("--hidden-dim", type=int, default=256, help="Hidden dimensionality")
    parser.add_argument("--epochs", type=int, default=25, help="Number of training epochs")
    parser.add_argument("--batch-size", type=int, default=4096, help="Batch size")
    parser.add_argument("--lr", type=float, default=1e-3, help="Learning rate")
    parser.add_argument("--kl-weight", type=float, default=0.1, help="KL divergence weight")
    parser.add_argument("--device", type=str, default="cuda", help="Training device (default: cuda)")
    parser.add_argument(
        "--validation-split",
        type=float,
        default=0.1,
        help="Fraction of samples reserved for validation",
    )
    parser.add_argument(
        "--standardize",
        action="store_true",
        help="Apply dataset mean/std from the NPZ metadata (recommended)",
    )
    parser.add_argument(
        "--seed",
        type=int,
        default=2025,
        help="Random seed for shuffling",
    )
    return parser.parse_args()


def set_seed(seed: int) -> None:
    torch.manual_seed(seed)
    np.random.seed(seed)


def load_dataset(path: Path, standardize: bool, device: torch.device) -> tuple[torch.Tensor, Dict[str, float]]:
    data = np.load(path)
    features = data["features"]
    mask = data["mask"].astype(bool)
    feats = features[mask]
    if feats.ndim != 2:
        raise ValueError("Expected feature array with shape (cells, dim)")

    meta: Dict[str, float | str] = {
        "num_cells": int(features.shape[0]),
        "num_valid": int(mask.sum()),
        "feature_dim": int(features.shape[1]),
    }

    x = torch.from_numpy(feats.astype(np.float32)).to(device)
    if standardize:
        mean = torch.from_numpy(data["mean"].astype(np.float32)).to(device)
        std = torch.from_numpy(data["std"].astype(np.float32)).to(device)
        x = (x - mean) / std
        meta["standardized"] = True
    else:
        meta["standardized"] = False
    return x, meta


def make_loaders(tensor: torch.Tensor, batch_size: int, val_split: float) -> tuple[DataLoader, DataLoader | None]:
    num_samples = tensor.shape[0]
    val_size = int(num_samples * val_split)
    if val_size > 0:
        perm = torch.randperm(num_samples, device=tensor.device)
        val_idx = perm[:val_size]
        train_idx = perm[val_size:]
        train_tensor = tensor.index_select(0, train_idx)
        val_tensor = tensor.index_select(0, val_idx)
        val_loader = DataLoader(TensorDataset(val_tensor), batch_size=batch_size, shuffle=False)
    else:
        train_tensor = tensor
        val_loader = None
    train_loader = DataLoader(TensorDataset(train_tensor), batch_size=batch_size, shuffle=True)
    return train_loader, val_loader


def train(args: argparse.Namespace) -> None:
    set_seed(args.seed)
    device = torch.device(args.device if torch.cuda.is_available() or args.device == "cpu" else "cpu")

    feats, meta = load_dataset(args.data, args.standardize, device)
    train_loader, val_loader = make_loaders(feats, args.batch_size, args.validation_split)

    input_dim = feats.shape[1]
    vae = VAE(input_dim=input_dim, hidden_dim=args.hidden_dim, latent_dim=args.latent_dim).to(device)
    optimizer = torch.optim.Adam(vae.parameters(), lr=args.lr)

    history: Dict[str, List[float]] = {"train_recon": [], "train_kl": [], "val_recon": [], "val_kl": []}

    for epoch in range(1, args.epochs + 1):
        vae.train()
        train_recon = 0.0
        train_kl = 0.0
        total = 0
        for (batch,) in train_loader:
            optimizer.zero_grad()
            recon, mu, logvar = vae(batch)
            recon_loss = F.mse_loss(recon, batch, reduction="mean")
            kl_loss = -0.5 * torch.mean(1 + logvar - mu.pow(2) - logvar.exp())
            loss = recon_loss + args.kl_weight * kl_loss
            loss.backward()
            optimizer.step()

            bs = batch.size(0)
            train_recon += recon_loss.item() * bs
            train_kl += kl_loss.item() * bs
            total += bs

        train_recon /= total
        train_kl /= total
        history["train_recon"].append(train_recon)
        history["train_kl"].append(train_kl)

        val_recon = float("nan")
        val_kl = float("nan")
        if val_loader is not None:
            vae.eval()
            recon_sum = 0.0
            kl_sum = 0.0
            count = 0
            with torch.no_grad():
                for (batch,) in val_loader:
                    recon, mu, logvar = vae(batch)
                    recon_loss = F.mse_loss(recon, batch, reduction="mean")
                    kl_loss = -0.5 * torch.mean(1 + logvar - mu.pow(2) - logvar.exp())
                    bs = batch.size(0)
                    recon_sum += recon_loss.item() * bs
                    kl_sum += kl_loss.item() * bs
                    count += bs
            val_recon = recon_sum / max(count, 1)
            val_kl = kl_sum / max(count, 1)
            history["val_recon"].append(val_recon)
            history["val_kl"].append(val_kl)

        print(
            f"Epoch {epoch:03d}/{args.epochs} - train_recon={train_recon:.4f} train_kl={train_kl:.4f}"
            + (" " + f"val_recon={val_recon:.4f} val_kl={val_kl:.4f}" if val_loader is not None else "")
        )

    args.output.parent.mkdir(parents=True, exist_ok=True)
    checkpoint = {
        "state_dict": vae.state_dict(),
        "config": {
            "input_dim": input_dim,
            "hidden_dim": args.hidden_dim,
            "latent_dim": args.latent_dim,
            "kl_weight": args.kl_weight,
            "standardized": bool(args.standardize),
            "mean": feats.mean(dim=0).cpu().numpy().tolist() if not args.standardize else None,
            "std": feats.std(dim=0).clamp_min(1e-6).cpu().numpy().tolist() if not args.standardize else None,
        },
        "dataset": {
            "path": str(args.data),
            "meta": meta,
        },
        "history": history,
    }
    torch.save(checkpoint, args.output)

    summary = {
        "output": str(args.output),
        "input_dim": input_dim,
        "latent_dim": args.latent_dim,
        "hidden_dim": args.hidden_dim,
        "kl_weight": args.kl_weight,
        "epochs": args.epochs,
        "train_recon": history["train_recon"][-1],
        "train_kl": history["train_kl"][-1],
        "val_recon": history["val_recon"][-1] if history["val_recon"] else None,
        "val_kl": history["val_kl"][-1] if history["val_kl"] else None,
    }
    print("Training complete:\n" + json.dumps(summary, indent=2))


if __name__ == "__main__":  # pragma: no cover
    args = parse_args()
    train(args)
